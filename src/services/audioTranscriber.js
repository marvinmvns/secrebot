import fs from 'fs/promises';
import path from 'path';
import { Readable } from 'stream';
import { spawn } from 'child_process';
import { WHISPER_CPP_PATH, WHISPER_CPP_MAIN_PATH, MODEL_OBJECT } from 'nodejs-whisper/dist/constants.js';
import ffmpeg from 'fluent-ffmpeg';
import Utils from '../utils/index.js'; // Ajustar caminho se necess√°rio
import { CONFIG, __dirname } from '../config/index.js'; // Ajustar caminho se necess√°rio
import JobQueue from './jobQueue.js';
import logger from '../utils/logger.js';
import { Ollama } from 'ollama';

// ============ Transcritor de √Åudio ============
class AudioTranscriber {
  constructor() {
    this.queue = new JobQueue(
      CONFIG.queues.whisperConcurrency,
      CONFIG.queues.memoryThresholdGB
    );
    this.ollamaClient = new Ollama({ host: CONFIG.llm.host });
  }

  async runWhisper(filePath, options) {
    const execPath = path.join(WHISPER_CPP_PATH, WHISPER_CPP_MAIN_PATH);
    const modelFile = MODEL_OBJECT[options.modelName];
    const modelPath = path.join(WHISPER_CPP_PATH, 'models', modelFile);
    const args = ['-m', modelPath, '-f', filePath, '-otxt', '-l', options.whisperOptions.language];

    // Log detalhado para debug
    logger.debug('üîß Whisper Debug Info:', {
      execPath,
      modelFile,
      modelPath,
      filePath,
      args: args.join(' '),
      cwd: WHISPER_CPP_PATH,
      timeout: CONFIG.audio.timeoutMs
    });

    // Verificar se o execut√°vel existe
    try {
      await fs.access(execPath, fs.constants.F_OK | fs.constants.X_OK);
      logger.debug(`‚úÖ Execut√°vel Whisper encontrado: ${execPath}`);
    } catch (error) {
      logger.error(`‚ùå Execut√°vel Whisper n√£o encontrado ou n√£o execut√°vel: ${execPath}`);
      throw new Error(`Whisper executable not found or not executable: ${execPath}`);
    }

    return new Promise((resolve, reject) => {
      logger.debug(`üöÄ Iniciando processo Whisper: ${execPath} ${args.join(' ')}`);
      
      const proc = spawn(execPath, args, { 
        cwd: WHISPER_CPP_PATH,
        stdio: ['pipe', 'pipe', 'pipe']
      });
      
      let stdout = '';
      let stderr = '';
      
      const timer = setTimeout(() => {
        logger.error('‚è∞ Whisper process timeout ap√≥s', CONFIG.audio.timeoutMs, 'ms');
        proc.kill('SIGKILL');
        reject(new Error(`Whisper process timed out after ${CONFIG.audio.timeoutMs}ms`));
      }, CONFIG.audio.timeoutMs);

      proc.stdout.on('data', d => {
        const data = d.toString();
        stdout += data;
        if (options.verbose) {
          logger.debug('üì§ Whisper STDOUT:', data.trim());
        }
      });

      proc.stderr.on('data', d => {
        const data = d.toString();
        stderr += data;
        logger.debug('üì• Whisper STDERR:', data.trim());
      });

      proc.on('error', err => {
        clearTimeout(timer);
        logger.error('‚ùå Whisper process error:', err);
        reject(err);
      });

      proc.on('close', code => {
        clearTimeout(timer);
        logger.debug(`üèÅ Whisper process finished with code: ${code}`);
        
        if (stdout) logger.debug('üì§ Final STDOUT:', stdout.trim());
        if (stderr) logger.debug('üì• Final STDERR:', stderr.trim());
        
        if (code === 0) {
          logger.debug('‚úÖ Whisper process completed successfully');
          resolve();
        } else {
          const errorMsg = stderr || `Whisper exited with code ${code}`;
          logger.error('‚ùå Whisper process failed:', errorMsg);
          reject(new Error(errorMsg));
        }
      });
    });
  }

  async transcribe(audioBuffer, inputFormat = 'ogg') {
    return this.queue.add(async () => {
      logger.service('üé§ Iniciando transcri√ß√£o de √°udio...');
      logger.debug(`üìä Audio buffer size: ${audioBuffer.length} bytes, format: ${inputFormat}`);
      
      const timestamp = Date.now();
      const tempOutputPath = path.join(__dirname, `audio_${timestamp}.wav`);

      try {
        // Verifica se o modelo est√° dispon√≠vel
        const modelFile = MODEL_OBJECT[CONFIG.audio.model];
        const modelPath = path.join(WHISPER_CPP_PATH, 'models', modelFile);
        
        try {
          await fs.access(modelPath);
        } catch (error) {
          throw new Error(`Modelo Whisper '${CONFIG.audio.model}' n√£o encontrado em ${modelPath}. Verifique se o modelo foi baixado.`);
        }

        await new Promise((resolve, reject) => {
          const inputStream = Readable.from(audioBuffer);
          ffmpeg(inputStream)
            .inputFormat(inputFormat)
            .outputOptions(`-ar ${CONFIG.audio.sampleRate}`)
            .toFormat('wav')
            .on('error', (err) => {
              logger.error('Erro no FFMPEG:', err);
              reject(err);
            })
            .on('end', resolve)
            .save(tempOutputPath);
        });
        
        const options = {
          modelName: CONFIG.audio.model,
          autoDownloadModelName: CONFIG.audio.model,
          verbose: true,
          removeWavFileAfterTranscription: false,
          withCuda: false,
          whisperOptions: { 
            outputInText: true, 
            language: CONFIG.audio.language 
          }
        };
        
        // Executa o Whisper com controle de timeout
        await this.runWhisper(tempOutputPath, options);
        
        const transcriptionPath = `${tempOutputPath}.txt`;
        const transcription = await fs.readFile(transcriptionPath, 'utf8');
        
        // Usa o m√©todo est√°tico de Utils para limpar arquivos
        await Utils.cleanupFile(tempOutputPath);
        await Utils.cleanupFile(transcriptionPath);
        
        logger.success('‚úÖ Transcri√ß√£o conclu√≠da.');
        return transcription.trim();
        
      } catch (err) {
        logger.error('‚ùå Erro na transcri√ß√£o de √°udio:', err);
        // Tenta limpar o arquivo tempor√°rio mesmo em caso de erro
        await Utils.cleanupFile(tempOutputPath);
        throw err;
      }
    });
  }

  async transcribeAndSummarize(audioBuffer, inputFormat = 'ogg') {
    try {
      logger.service('üé§ Iniciando transcri√ß√£o e resumo de √°udio...');
      
      const transcription = await this.transcribe(audioBuffer, inputFormat);
      
      logger.service('üß† Gerando resumo com LLM...');
      const summaryPrompt = `Analise a seguinte transcri√ß√£o de √°udio e crie um resumo estruturado e claro:

TRANSCRI√á√ÉO:
"${transcription}"

O resumo deve incluir os principais pontos discutidos, eventos importantes e qualquer informa√ß√£o relevante mencionada. Evite detalhes excessivos e mantenha o foco nos aspectos mais significativos da conversa. O resumo deve ser escrito em portugu√™s e ser facilmente compreens√≠vel.
Mantenha o resumo conciso mas informativo, destacando os pontos mais importantes do √°udio.`;

      const summary = await this.ollamaClient.generate({
        model: CONFIG.llm.model,
        prompt: summaryPrompt,
        stream: false
      });

      logger.success('‚úÖ Transcri√ß√£o e resumo conclu√≠dos.');
      
      return {
        transcription: transcription,
        summary: summary.response,
        combined: `üé§ **TRANSCRI√á√ÉO COMPLETA:**\n\n${transcription}\n\n---\n\n${summary.response}`
      };
      
    } catch (err) {
      logger.error('‚ùå Erro na transcri√ß√£o e resumo de √°udio:', err);
      throw err;
    }
  }
}

export default AudioTranscriber;
