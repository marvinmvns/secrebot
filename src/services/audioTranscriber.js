import fs from 'fs/promises';
import path from 'path';
import { Readable } from 'stream';
import { spawn } from 'child_process';
import { WHISPER_CPP_PATH, WHISPER_CPP_MAIN_PATH, MODEL_OBJECT } from 'nodejs-whisper/dist/constants.js';
import ffmpeg from 'fluent-ffmpeg';
import Utils from '../utils/index.js'; // Ajustar caminho se necess√°rio
import { CONFIG, __dirname } from '../config/index.js'; // Ajustar caminho se necess√°rio
import JobQueue from './jobQueue.js';
import logger from '../utils/logger.js';
import { Ollama } from 'ollama';

// ============ Transcritor de √Åudio ============
class AudioTranscriber {
  constructor() {
    this.queue = new JobQueue(
      CONFIG.queues.whisperConcurrency,
      CONFIG.queues.memoryThresholdGB
    );
    this.ollamaClient = new Ollama({ host: CONFIG.llm.host });
  }

  async runWhisper(filePath, options) {
    const execPath = path.join(WHISPER_CPP_PATH, WHISPER_CPP_MAIN_PATH);
    const modelFile = MODEL_OBJECT[options.modelName];
    const modelPath = path.join(WHISPER_CPP_PATH, 'models', modelFile);
    const args = ['-m', modelPath, '-f', filePath, '-otxt', '-l', options.whisperOptions.language];

    return new Promise((resolve, reject) => {
      const proc = spawn(execPath, args, { cwd: WHISPER_CPP_PATH });
      let stderr = '';
      const timer = setTimeout(() => {
        proc.kill('SIGKILL');
        reject(new Error('Whisper process timed out'));
      }, CONFIG.audio.timeoutMs);

      proc.stderr.on('data', d => {
        stderr += d.toString();
      });
      proc.on('error', err => {
        clearTimeout(timer);
        reject(err);
      });
      proc.on('close', code => {
        clearTimeout(timer);
        if (code === 0) {
          resolve();
        } else {
          reject(new Error(stderr || `Whisper exited with code ${code}`));
        }
      });
    });
  }

  async transcribe(audioBuffer, inputFormat = 'ogg') {
    return this.queue.add(async () => {
      logger.service('üé§ Iniciando transcri√ß√£o de √°udio...');
      const timestamp = Date.now();
      const tempOutputPath = path.join(__dirname, `audio_${timestamp}.wav`);

      try {
        // Verifica se o modelo est√° dispon√≠vel
        const modelFile = MODEL_OBJECT[CONFIG.audio.model];
        const modelPath = path.join(WHISPER_CPP_PATH, 'models', modelFile);
        
        try {
          await fs.access(modelPath);
        } catch (error) {
          throw new Error(`Modelo Whisper '${CONFIG.audio.model}' n√£o encontrado em ${modelPath}. Verifique se o modelo foi baixado.`);
        }

        await new Promise((resolve, reject) => {
          const inputStream = Readable.from(audioBuffer);
          ffmpeg(inputStream)
            .inputFormat(inputFormat)
            .outputOptions(`-ar ${CONFIG.audio.sampleRate}`)
            .toFormat('wav')
            .on('error', (err) => {
              logger.error('Erro no FFMPEG:', err);
              reject(err);
            })
            .on('end', resolve)
            .save(tempOutputPath);
        });
        
        const options = {
          modelName: CONFIG.audio.model,
          autoDownloadModelName: CONFIG.audio.model,
          verbose: true,
          removeWavFileAfterTranscription: false,
          withCuda: false,
          whisperOptions: { 
            outputInText: true, 
            language: CONFIG.audio.language 
          }
        };
        
        // Executa o Whisper com controle de timeout
        await this.runWhisper(tempOutputPath, options);
        
        const transcriptionPath = `${tempOutputPath}.txt`;
        const transcription = await fs.readFile(transcriptionPath, 'utf8');
        
        // Usa o m√©todo est√°tico de Utils para limpar arquivos
        await Utils.cleanupFile(tempOutputPath);
        await Utils.cleanupFile(transcriptionPath);
        
        logger.success('‚úÖ Transcri√ß√£o conclu√≠da.');
        return transcription.trim();
        
      } catch (err) {
        logger.error('‚ùå Erro na transcri√ß√£o de √°udio:', err);
        // Tenta limpar o arquivo tempor√°rio mesmo em caso de erro
        await Utils.cleanupFile(tempOutputPath);
        throw err;
      }
    });
  }

  async transcribeAndSummarize(audioBuffer, inputFormat = 'ogg') {
    try {
      logger.service('üé§ Iniciando transcri√ß√£o e resumo de √°udio...');
      
      const transcription = await this.transcribe(audioBuffer, inputFormat);
      
      logger.service('üß† Gerando resumo com LLM...');
      const summaryPrompt = `Analise a seguinte transcri√ß√£o de √°udio e crie um resumo estruturado e claro:

TRANSCRI√á√ÉO:
"${transcription}"

O resumo deve incluir os principais pontos discutidos, eventos importantes e qualquer informa√ß√£o relevante mencionada. Evite detalhes excessivos e mantenha o foco nos aspectos mais significativos da conversa. O resumo deve ser escrito em portugu√™s e ser facilmente compreens√≠vel.
Mantenha o resumo conciso mas informativo, destacando os pontos mais importantes do √°udio.`;

      const summary = await this.ollamaClient.generate({
        model: CONFIG.llm.model,
        prompt: summaryPrompt,
        stream: false
      });

      logger.success('‚úÖ Transcri√ß√£o e resumo conclu√≠dos.');
      
      return {
        transcription: transcription,
        summary: summary.response,
        combined: `üé§ **TRANSCRI√á√ÉO COMPLETA:**\n\n${transcription}\n\n---\n\n${summary.response}`
      };
      
    } catch (err) {
      logger.error('‚ùå Erro na transcri√ß√£o e resumo de √°udio:', err);
      throw err;
    }
  }
}

export default AudioTranscriber;
