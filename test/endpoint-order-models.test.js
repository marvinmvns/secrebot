#!/usr/bin/env node

/**
 * Teste para verificar se a mudan√ßa de ordem dos endpoints afeta a listagem de modelos
 */

import test from 'node:test';
import assert from 'node:assert';
import LLMService from '../src/services/llmService.js';
import OllamaApiPool from '../src/services/ollamaApiPool.js';
import ChatGPTAPIClient from '../src/services/chatgptApiClient.js';

test('Endpoint Order and Model Listing - Verificar listagem ap√≥s mudan√ßa de ordem', async () => {
  console.log('üß™ Testando se mudan√ßa de ordem afeta listagem de modelos...\n');

  try {
    // 1. Testar ChatGPTAPIClient diretamente
    console.log('1. Testando ChatGPTAPIClient diretamente...');
    
    try {
      // Usar uma API key falsa para teste de estrutura
      const chatgptClient = new ChatGPTAPIClient('https://api.openai.com', 'fake-key-for-test');
      
      console.log('   ‚úÖ ChatGPTAPIClient criado com sucesso');
      console.log(`   üìä Base URL: ${chatgptClient.baseURL}`);
      console.log(`   üìä Modelo padr√£o: ${chatgptClient.defaultModel}`);
      
      try {
        const models = await chatgptClient.listModels();
        console.log(`   ‚úÖ listModels funcionou: ${models.models.length} modelos`);
        console.log(`   üìã Primeiros modelos: ${models.models.slice(0, 3).map(m => m.name).join(', ')}`);
      } catch (error) {
        console.log(`   ‚ö†Ô∏è listModels falhou (esperado com API key falsa): ${error.message}`);
        // Isso √© esperado com API key falsa
      }
    } catch (error) {
      console.log(`   ‚ùå Erro ao criar ChatGPTAPIClient: ${error.message}`);
    }

    // 2. Testar diferentes configura√ß√µes de endpoints
    console.log('\n2. Testando diferentes configura√ß√µes de endpoints...');
    
    const testConfigurations = [
      {
        name: 'ChatGPT primeiro',
        endpoints: [
          { url: 'https://api.openai.com', type: 'chatgpt', enabled: true, apikey: 'fake-key' },
          { url: 'http://localhost:11434', type: 'ollama', enabled: true },
          { url: 'http://localhost:8080', type: 'rkllama', enabled: true }
        ]
      },
      {
        name: 'Ollama primeiro', 
        endpoints: [
          { url: 'http://localhost:11434', type: 'ollama', enabled: true },
          { url: 'https://api.openai.com', type: 'chatgpt', enabled: true, apikey: 'fake-key' },
          { url: 'http://localhost:8080', type: 'rkllama', enabled: true }
        ]
      },
      {
        name: 'RKLLama primeiro',
        endpoints: [
          { url: 'http://localhost:8080', type: 'rkllama', enabled: true },
          { url: 'http://localhost:11434', type: 'ollama', enabled: true },
          { url: 'https://api.openai.com', type: 'chatgpt', enabled: true, apikey: 'fake-key' }
        ]
      }
    ];

    for (const config of testConfigurations) {
      console.log(`   üîß Testando configura√ß√£o: ${config.name}`);
      
      // Simular configura√ß√£o diferente
      const mockConfig = {
        ollamaApi: {
          enabled: true,
          endpoints: config.endpoints,
          mode: 'api'
        }
      };

      try {
        // Criar pool tempor√°rio com configura√ß√£o espec√≠fica
        const pool = new OllamaApiPool();
        
        // Simular diferentes ordens e verificar detec√ß√£o de tipos
        config.endpoints.forEach((endpoint, index) => {
          const detectedType = pool.getEndpointType(endpoint);
          console.log(`      ${index + 1}. ${endpoint.url} ‚Üí Tipo detectado: ${detectedType} (esperado: ${endpoint.type})`);
          
          const typeMatch = detectedType === endpoint.type;
          console.log(`         Match: ${typeMatch ? '‚úÖ' : '‚ùå'}`);
        });

      } catch (error) {
        console.log(`      ‚ùå Erro na configura√ß√£o ${config.name}: ${error.message}`);
      }
    }

    // 3. Testar LLMService com diferentes configura√ß√µes
    console.log('\n3. Testando LLMService...');
    
    try {
      const llmService = new LLMService();
      console.log('   ‚úÖ LLMService criado');
      
      // Verificar se m√©todo listModels funciona
      console.log('   üìã Testando listModels do LLMService...');
      try {
        const models = await llmService.listModelsFromAllEndpoints();
        console.log(`   ‚úÖ listModelsFromAllEndpoints funcionou`);
        console.log(`   üìä Total de modelos √∫nicos: ${models.uniqueModels.length}`);
        console.log(`   üìä Endpoints consultados: ${models.endpoints.length}`);
        console.log(`   üìä Total geral de modelos: ${models.totalModels}`);
        
        if (models.uniqueModels.length > 0) {
          console.log(`   üìã Alguns modelos: ${models.uniqueModels.slice(0, 5).join(', ')}`);
        }
      } catch (error) {
        console.log(`   ‚ö†Ô∏è listModelsFromAllEndpoints falhou: ${error.message}`);
      }

    } catch (error) {
      console.log(`   ‚ùå Erro ao criar LLMService: ${error.message}`);
    }

    // 4. Verificar ordem de prioridade
    console.log('\n4. Testando sistema de prioridades...');
    
    const pool = new OllamaApiPool();
    
    // Verificar se endpoints s√£o ordenados corretamente por prioridade
    const testEndpoints = [
      { url: 'http://test1.com', type: 'ollama', priority: 3, enabled: true },
      { url: 'http://test2.com', type: 'chatgpt', priority: 1, enabled: true },
      { url: 'http://test3.com', type: 'rkllama', priority: 2, enabled: true }
    ];
    
    console.log('   üìä Endpoints de teste (por ordem de cria√ß√£o):');
    testEndpoints.forEach((ep, i) => {
      console.log(`      ${i + 1}. ${ep.url} (tipo: ${ep.type}, prioridade: ${ep.priority})`);
    });
    
    // Ordenar por prioridade (como faz o frontend)
    const sortedByPriority = [...testEndpoints].sort((a, b) => (a.priority || 999) - (b.priority || 999));
    
    console.log('   üìä Endpoints ordenados por prioridade:');
    sortedByPriority.forEach((ep, i) => {
      console.log(`      ${i + 1}. ${ep.url} (tipo: ${ep.type}, prioridade: ${ep.priority})`);
    });

    console.log('\n‚úÖ Teste de ordem de endpoints e modelos conclu√≠do');

  } catch (error) {
    console.error('‚ùå Erro geral no teste:', error);
    throw error;
  }
});

test('ChatGPT Models Detection - Teste espec√≠fico para ChatGPT', async () => {
  console.log('üß™ Testando especificamente a detec√ß√£o de modelos ChatGPT...\n');

  try {
    // Testar diferentes cen√°rios com ChatGPT
    console.log('1. Testando detec√ß√£o de endpoint ChatGPT...');
    
    const pool = new OllamaApiPool();
    
    const chatgptEndpoints = [
      { url: 'https://api.openai.com', type: 'chatgpt' },
      { url: 'https://api.openai.com/v1', type: 'chatgpt' },
      { url: 'http://localhost:11434', type: 'ollama' },
      { url: 'http://localhost:8080', type: 'rkllama' }
    ];

    chatgptEndpoints.forEach(endpoint => {
      const detectedType = pool.getEndpointType(endpoint);
      const isChatGPT = pool.isChatGPTEndpoint(endpoint);
      console.log(`   üìä ${endpoint.url}:`);
      console.log(`      - Tipo configurado: ${endpoint.type}`);
      console.log(`      - Tipo detectado: ${detectedType}`);
      console.log(`      - √â ChatGPT: ${isChatGPT}`);
      console.log(`      - Match: ${detectedType === endpoint.type ? '‚úÖ' : '‚ùå'}`);
    });

    // 2. Testar listModels com diferentes API keys
    console.log('\n2. Testando listModels com diferentes cen√°rios...');
    
    console.log('   üîë Testando sem API key...');
    try {
      const client = new ChatGPTAPIClient('https://api.openai.com');
      const models = await client.listModels();
      console.log(`      - Funcionou sem API key: ‚úÖ (${models.models.length} modelos)`);
    } catch (error) {
      console.log(`      - Falhou sem API key: ‚ö†Ô∏è (esperado) - ${error.message.substring(0, 50)}...`);
    }

    console.log('   üîë Testando com API key falsa...');
    try {
      const client = new ChatGPTAPIClient('https://api.openai.com', 'fake-key');
      const models = await client.listModels();
      console.log(`      - Funcionou com key falsa: ‚ö†Ô∏è (inesperado) - ${models.models.length} modelos`);
    } catch (error) {
      console.log(`      - Falhou com key falsa: ‚úÖ (esperado) - ${error.message.substring(0, 50)}...`);
    }

    console.log('\n3. Verificando estrutura de resposta...');
    
    // Testar estrutura de resposta esperada
    const expectedStructure = {
      models: [],
      success: true,
      url: 'https://api.openai.com',
      type: 'chatgpt',
      timestamp: new Date().toISOString()
    };

    console.log('   üìã Estrutura esperada para resposta de modelos:');
    console.log('      - models: Array de modelos');
    console.log('      - success: boolean');
    console.log('      - url: string com endpoint');
    console.log('      - type: "chatgpt"');
    console.log('      - timestamp: ISO string');

    console.log('\n‚úÖ Teste espec√≠fico ChatGPT conclu√≠do');

  } catch (error) {
    console.error('‚ùå Erro no teste ChatGPT:', error);
    throw error;
  }
});