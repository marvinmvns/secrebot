import OllamaAPIClient from './ollamaApiClient.js';
import RKLlamaAPIClient from './rkllamaApiClient.js';
import logger from '../utils/logger.js';
import { CONFIG, getDynamicConfig } from '../config/index.js';

class OllamaAPIPool {
  constructor(configService = null) {
    this.configService = configService;
    this.clients = [];
    this.currentIndex = 0;
    this.lastHealthCheck = 0;
    this.healthCheckInterval = null;
    this.requestCount = 0; // Para tracking de balanceamento
    this.initialize();
  }

  async getEffectiveConfig() {
    let mongoConfig = null;
    if (this.configService) {
      try {
        mongoConfig = await this.configService.getConfig();
      } catch (error) {
        logger.warn('‚ö†Ô∏è Erro ao obter configura√ß√£o do MongoDB para OllamaAPI, usando configura√ß√£o padr√£o:', error.message);
      }
    }
    return getDynamicConfig(mongoConfig);
  }

  // Helper function to detect RKLLama endpoints (by configured type)
  isRKLlamaEndpoint(endpoint) {
    // Check configured type first, fallback to port detection for backward compatibility
    if (endpoint.type) {
      return endpoint.type === 'rkllama';
    }
    
    // Fallback: detect by port for existing configurations
    try {
      const parsedUrl = new URL(endpoint.url || endpoint);
      return parsedUrl.port === '8080';
    } catch (error) {
      logger.warn(`‚ö†Ô∏è URL inv√°lida para detec√ß√£o RKLLama: ${endpoint.url || endpoint}`);
      return false;
    }
  }

  // Create appropriate client based on endpoint type
  createClient(endpoint) {
    const isRKLlama = this.isRKLlamaEndpoint(endpoint);
    
    if (isRKLlama) {
      logger.info(`ü§ñ Criando cliente RKLLama para: ${endpoint.url}`);
      return new RKLlamaAPIClient(endpoint.url);
    } else {
      logger.info(`üß† Criando cliente Ollama para: ${endpoint.url}`);
      return new OllamaAPIClient(endpoint.url);
    }
  }

  async initialize() {
    logger.info('üîß Inicializando pool de APIs Ollama...');
    
    // Stop existing health check interval if running
    this.stopHealthCheckInterval();
    
    const effectiveConfig = await this.getEffectiveConfig();
    
    if (!effectiveConfig.ollamaApi.enabled || !effectiveConfig.ollamaApi.endpoints.length) {
      logger.warn('‚ö†Ô∏è OllamaAPI n√£o habilitado ou sem endpoints configurados');
      this.clients = [];
      return;
    }

    this.clients = effectiveConfig.ollamaApi.endpoints
      .filter(endpoint => endpoint.enabled)
      .map(endpoint => {
        const client = this.createClient(endpoint);
        client.endpoint = endpoint;
        client.retryCount = 0;
        
        const clientType = this.isRKLlamaEndpoint(endpoint) ? 'RKLLama' : 'Ollama';
        logger.info(`üì° Endpoint ${clientType} configurado: ${endpoint.url} (prioridade: ${endpoint.priority})`);
        return client;
      });

    this.clients.sort((a, b) => a.endpoint.priority - b.endpoint.priority);
    
    if (this.clients.length > 0) {
      logger.success(`‚úÖ Pool Ollama inicializado com ${this.clients.length} endpoints`);
      this.startHealthCheckInterval();
      
      // Load saved models for RKLLama endpoints
      await this.loadSavedModels();
    } else {
      logger.warn('‚ö†Ô∏è Nenhum endpoint Ollama habilitado encontrado');
    }
  }

  startHealthCheckInterval() {
    this.healthCheckInterval = setInterval(async () => {
      await this.performHealthChecks();
    }, CONFIG.ollamaApi.loadBalancing.healthCheckInterval);
  }

  stopHealthCheckInterval() {
    if (this.healthCheckInterval) {
      clearInterval(this.healthCheckInterval);
      this.healthCheckInterval = null;
      logger.debug('üõë Health check interval Ollama parado');
    }
  }

  async performHealthChecks() {
    // Check if the service is still enabled
    const isServiceEnabled = await this.isEnabled();
    if (!isServiceEnabled) {
      logger.debug('üõë OllamaAPI desabilitado, parando health checks');
      this.stopHealthCheckInterval();
      return;
    }

    if (this.clients.length === 0) {
      logger.debug('üõë Nenhum cliente Ollama dispon√≠vel para health check');
      return;
    }

    logger.debug('üîç Executando health checks nos endpoints Ollama...');
    
    const healthPromises = this.clients.map(async (client) => {
      try {
        await client.checkHealth();
        client.retryCount = 0;
      } catch (error) {
        client.retryCount++;
        logger.warn(`‚ö†Ô∏è Health check falhou para ${client.baseURL} (tentativa ${client.retryCount})`);
      }
    });

    await Promise.allSettled(healthPromises);
  }

  getHealthyClients() {
    return this.clients.filter(client => 
      client.isHealthy && client.retryCount < client.endpoint.maxRetries
    );
  }

  async selectClientByStrategy(healthyClients) {
    const effectiveConfig = await this.getEffectiveConfig();
    const strategy = effectiveConfig.ollamaApi.loadBalancing.strategy;
    
    logger.debug(`üéØ Aplicando estrat√©gia: ${strategy} para ${healthyClients.length} clientes`);
    
    switch (strategy) {
      case 'round_robin':
        return this.selectRoundRobin(healthyClients);
      
      case 'priority':
        return this.selectByPriority(healthyClients);
      
      case 'queue_length':
        return this.selectByLoad(healthyClients);
      
      default:
        logger.warn(`‚ö†Ô∏è Estrat√©gia desconhecida: ${strategy}, usando priority`);
        return this.selectByPriority(healthyClients);
    }
  }

  selectRoundRobin(clients) {
    if (clients.length === 0) return null;
    
    const selectedIndex = this.currentIndex % clients.length;
    const client = clients[selectedIndex];
    this.currentIndex = (this.currentIndex + 1) % clients.length;
    
    logger.debug(`üîÑ Round-robin selecionou: ${client.baseURL} (√≠ndice: ${selectedIndex}/${clients.length})`);
    return client;
  }

  selectByPriority(clients) {
    if (clients.length === 0) return null;
    
    const client = clients[0];
    logger.debug(`‚≠ê Prioridade selecionou: ${client.baseURL} (prioridade: ${client.endpoint.priority})`);
    return client;
  }

  selectByLoad(clients) {
    if (clients.length === 0) return null;
    
    // Log informa√ß√µes de todos os clientes para debug
    const clientStats = clients.map(c => ({
      url: c.baseURL,
      type: c.constructor.name,
      activeRequests: c.activeRequests,
      totalRequests: c.totalRequests,
      runningModels: c.runningModels?.length || 0,
      loadScore: c.getLoadScore()
    }));
    logger.debug('üìä Estat√≠sticas de clientes para sele√ß√£o:', clientStats);
    
    const client = clients.reduce((best, current) => {
      const bestScore = best.getLoadScore();
      const currentScore = current.getLoadScore();
      return currentScore < bestScore ? current : best;
    });

    logger.debug(`üìä Load balancing selecionou: ${client.baseURL} (score: ${client.getLoadScore()}, ativo: ${client.activeRequests})`);
    return client;
  }

  async selectBestClient() {
    const healthyClients = this.getHealthyClients();
    
    if (healthyClients.length === 0) {
      logger.error('‚ùå Nenhum endpoint Ollama saud√°vel dispon√≠vel');
      throw new Error('No healthy Ollama API endpoints available');
    }

    // Atualiza informa√ß√µes de carga para todos os clientes saud√°veis
    logger.debug('üìä Atualizando informa√ß√µes de carga para balanceamento...');
    await Promise.allSettled(
      healthyClients.map(async (client) => {
        try {
          await client.listRunningModels();
          const processingStatus = client.getProcessingStatus();
          logger.debug(`üìä ${client.baseURL}: ativo=${processingStatus.activeRequests}, total=${processingStatus.totalRequests}, score=${client.getLoadScore()}`);
        } catch (error) {
          logger.debug(`‚ö†Ô∏è Erro ao obter status de ${client.baseURL}: ${error.message}`);
        }
      })
    );

    const selectedClient = await this.selectClientByStrategy(healthyClients);
    const effectiveConfig = await this.getEffectiveConfig();
    logger.info(`üéØ Cliente selecionado: ${selectedClient.baseURL} (estrat√©gia: ${effectiveConfig.ollamaApi.loadBalancing.strategy})`);
    
    return selectedClient;
  }

  // ============ Generate Methods ============
  async generateWithFallback(options = {}) {
    const healthyClients = this.getHealthyClients();
    
    if (healthyClients.length === 0) {
      logger.warn('‚ö†Ô∏è Nenhum endpoint Ollama API saud√°vel dispon√≠vel');
      throw new Error('No healthy Ollama API endpoints available');
    }

    let lastError;
    
    for (const client of healthyClients) {
      try {
        logger.info(`üéØ Tentando gera√ß√£o com ${client.baseURL}`);
        
        const result = await client.generate(options);
        
        logger.success(`‚úÖ Gera√ß√£o bem-sucedida via ${client.baseURL}`);
        return result;
        
      } catch (error) {
        lastError = error;
        client.retryCount++;
        
        logger.warn(`‚ö†Ô∏è Falha na gera√ß√£o via ${client.baseURL}: ${error.message}`);
        
        if (client.retryCount >= client.endpoint.maxRetries) {
          client.isHealthy = false;
          logger.error(`‚ùå Endpoint ${client.baseURL} marcado como n√£o saud√°vel ap√≥s ${client.retryCount} falhas`);
        }
        
        if (healthyClients.indexOf(client) < healthyClients.length - 1) {
          logger.info(`üîÑ Tentando pr√≥ximo endpoint em ${CONFIG.ollamaApi.retryDelay}ms...`);
          await new Promise(resolve => setTimeout(resolve, CONFIG.ollamaApi.retryDelay));
        }
      }
    }
    
    logger.error(`‚ùå Todos os endpoints Ollama API falharam. √öltimo erro: ${lastError?.message}`);
    throw new Error(`All Ollama API endpoints failed. Last error: ${lastError?.message}`);
  }

  async generate(options = {}) {
    logger.service('ü§ñ Iniciando gera√ß√£o via Ollama API...');
    
    // Use balanceamento adequado baseado na estrat√©gia configurada
    return await this.generateWithLoadBalancing(options);
  }

  async generateWithLoadBalancing(options = {}) {
    this.requestCount++;
    const effectiveConfig = await this.getEffectiveConfig();
    
    logger.info(`üéØ Requisi√ß√£o #${this.requestCount} - Iniciando balanceamento (estrat√©gia: ${effectiveConfig.ollamaApi.loadBalancing.strategy})`);
    
    const selectedClient = await this.selectBestClient();
    
    if (!selectedClient) {
      logger.warn('‚ö†Ô∏è Nenhum endpoint Ollama API saud√°vel dispon√≠vel');
      throw new Error('No healthy Ollama API endpoints available');
    }

    const startTime = Date.now();
    try {
      const processingStatus = selectedClient.getProcessingStatus();
      logger.info(`üéØ Req #${this.requestCount}: Usando ${selectedClient.baseURL} (ativo: ${processingStatus.activeRequests}, score: ${selectedClient.getLoadScore()})`);
      
      const result = await selectedClient.generate(options);
      
      const duration = Date.now() - startTime;
      logger.success(`‚úÖ Req #${this.requestCount}: Gera√ß√£o bem-sucedida via ${selectedClient.baseURL} em ${duration}ms`);
      return result;
      
    } catch (error) {
      selectedClient.retryCount++;
      const duration = Date.now() - startTime;
      logger.warn(`‚ö†Ô∏è Req #${this.requestCount}: Falha via ${selectedClient.baseURL} ap√≥s ${duration}ms: ${error.message}`);
      
      // Se falhar, marca como n√£o saud√°vel e tenta com fallback
      if (selectedClient.retryCount >= selectedClient.endpoint.maxRetries) {
        selectedClient.isHealthy = false;
        logger.error(`‚ùå Endpoint ${selectedClient.baseURL} marcado como n√£o saud√°vel ap√≥s ${selectedClient.retryCount} falhas`);
      }
      
      // Fallback para outros endpoints dispon√≠veis
      logger.info(`üîÑ Req #${this.requestCount}: Tentando fallback para outros endpoints...`);
      return await this.generateWithFallback(options);
    }
  }

  // ============ Chat Methods ============
  async chatWithFallback(options = {}) {
    const healthyClients = this.getHealthyClients();
    
    if (healthyClients.length === 0) {
      logger.warn('‚ö†Ô∏è Nenhum endpoint Ollama API saud√°vel dispon√≠vel');
      throw new Error('No healthy Ollama API endpoints available');
    }

    let lastError;
    
    for (const client of healthyClients) {
      try {
        logger.info(`üéØ Tentando chat com ${client.baseURL}`);
        
        const result = await client.chat(options);
        
        logger.success(`‚úÖ Chat bem-sucedido via ${client.baseURL}`);
        return result;
        
      } catch (error) {
        lastError = error;
        client.retryCount++;
        
        logger.warn(`‚ö†Ô∏è Falha no chat via ${client.baseURL}: ${error.message}`);
        
        if (client.retryCount >= client.endpoint.maxRetries) {
          client.isHealthy = false;
          logger.error(`‚ùå Endpoint ${client.baseURL} marcado como n√£o saud√°vel ap√≥s ${client.retryCount} falhas`);
        }
        
        if (healthyClients.indexOf(client) < healthyClients.length - 1) {
          logger.info(`üîÑ Tentando pr√≥ximo endpoint em ${CONFIG.ollamaApi.retryDelay}ms...`);
          await new Promise(resolve => setTimeout(resolve, CONFIG.ollamaApi.retryDelay));
        }
      }
    }
    
    logger.error(`‚ùå Todos os endpoints Ollama API falharam. √öltimo erro: ${lastError?.message}`);
    throw new Error(`All Ollama API endpoints failed. Last error: ${lastError?.message}`);
  }

  async chat(options = {}) {
    logger.service('üí¨ Iniciando chat via Ollama API...');
    
    // Use balanceamento adequado baseado na estrat√©gia configurada
    return await this.chatWithLoadBalancing(options);
  }

  async chatWithLoadBalancing(options = {}) {
    this.requestCount++;
    const effectiveConfig = await this.getEffectiveConfig();
    
    logger.info(`üéØ Chat #${this.requestCount} - Iniciando balanceamento (estrat√©gia: ${effectiveConfig.ollamaApi.loadBalancing.strategy})`);
    
    const selectedClient = await this.selectBestClient();
    
    if (!selectedClient) {
      logger.warn('‚ö†Ô∏è Nenhum endpoint Ollama API saud√°vel dispon√≠vel');
      throw new Error('No healthy Ollama API endpoints available');
    }

    const startTime = Date.now();
    try {
      const processingStatus = selectedClient.getProcessingStatus();
      logger.info(`üéØ Chat #${this.requestCount}: Usando ${selectedClient.baseURL} (ativo: ${processingStatus.activeRequests}, score: ${selectedClient.getLoadScore()})`);
      
      const result = await selectedClient.chat(options);
      
      const duration = Date.now() - startTime;
      logger.success(`‚úÖ Chat #${this.requestCount}: Chat bem-sucedido via ${selectedClient.baseURL} em ${duration}ms`);
      return result;
      
    } catch (error) {
      selectedClient.retryCount++;
      const duration = Date.now() - startTime;
      logger.warn(`‚ö†Ô∏è Chat #${this.requestCount}: Falha via ${selectedClient.baseURL} ap√≥s ${duration}ms: ${error.message}`);
      
      // Se falhar, marca como n√£o saud√°vel e tenta com fallback
      if (selectedClient.retryCount >= selectedClient.endpoint.maxRetries) {
        selectedClient.isHealthy = false;
        logger.error(`‚ùå Endpoint ${selectedClient.baseURL} marcado como n√£o saud√°vel ap√≥s ${selectedClient.retryCount} falhas`);
      }
      
      // Fallback para outros endpoints dispon√≠veis
      logger.info(`üîÑ Chat #${this.requestCount}: Tentando fallback para outros endpoints...`);
      return await this.chatWithFallback(options);
    }
  }

  // ============ Model Management Methods ============
  async listModels() {
    try {
      const client = await this.selectBestClient();
      return await client.listModels();
    } catch (error) {
      return await this.executeWithFallback('listModels');
    }
  }

  async showModel(model, verbose = false) {
    try {
      const client = await this.selectBestClient();
      return await client.showModel(model, verbose);
    } catch (error) {
      return await this.executeWithFallback('showModel', model, verbose);
    }
  }

  async pullModel(model, stream = false) {
    try {
      const client = await this.selectBestClient();
      return await client.pullModel(model, stream);
    } catch (error) {
      return await this.executeWithFallback('pullModel', model, stream);
    }
  }

  async createModel(options = {}) {
    try {
      const client = await this.selectBestClient();
      return await client.createModel(options);
    } catch (error) {
      return await this.executeWithFallback('createModel', options);
    }
  }

  async deleteModel(model) {
    try {
      const client = await this.selectBestClient();
      return await client.deleteModel(model);
    } catch (error) {
      return await this.executeWithFallback('deleteModel', model);
    }
  }

  async copyModel(source, destination) {
    try {
      const client = await this.selectBestClient();
      return await client.copyModel(source, destination);
    } catch (error) {
      return await this.executeWithFallback('copyModel', source, destination);
    }
  }

  // ============ Other Methods ============
  async generateEmbeddings(model, input, options = {}) {
    try {
      const client = await this.selectBestClient();
      return await client.generateEmbeddings(model, input, options);
    } catch (error) {
      return await this.executeWithFallback('generateEmbeddings', model, input, options);
    }
  }

  async listRunningModels() {
    try {
      const client = await this.selectBestClient();
      return await client.listRunningModels();
    } catch (error) {
      return await this.executeWithFallback('listRunningModels');
    }
  }

  // ============ Generic Fallback Method ============
  async executeWithFallback(method, ...args) {
    const healthyClients = this.getHealthyClients();
    
    if (healthyClients.length === 0) {
      logger.warn('‚ö†Ô∏è Nenhum endpoint Ollama API saud√°vel dispon√≠vel');
      throw new Error('No healthy Ollama API endpoints available');
    }

    let lastError;
    
    for (const client of healthyClients) {
      try {
        logger.debug(`üéØ Tentando ${method} com ${client.baseURL}`);
        const result = await client[method](...args);
        logger.success(`‚úÖ ${method} bem-sucedido via ${client.baseURL}`);
        return result;
      } catch (error) {
        lastError = error;
        client.retryCount++;
        
        logger.warn(`‚ö†Ô∏è Falha em ${method} via ${client.baseURL}: ${error.message}`);
        
        if (client.retryCount >= client.endpoint.maxRetries) {
          client.isHealthy = false;
          logger.error(`‚ùå Endpoint ${client.baseURL} marcado como n√£o saud√°vel ap√≥s ${client.retryCount} falhas`);
        }
        
        if (healthyClients.indexOf(client) < healthyClients.length - 1) {
          logger.debug(`üîÑ Tentando pr√≥ximo endpoint para ${method}...`);
          await new Promise(resolve => setTimeout(resolve, CONFIG.ollamaApi.retryDelay));
        }
      }
    }
    
    logger.error(`‚ùå Todos os endpoints falharam para ${method}. √öltimo erro: ${lastError?.message}`);
    throw new Error(`All Ollama API endpoints failed. Last error: ${lastError?.message}`);
  }

  // ============ Pool Status ============
  async getPoolStatus() {
    const effectiveConfig = await this.getEffectiveConfig();
    const status = {
      enabled: effectiveConfig.ollamaApi.enabled,
      mode: effectiveConfig.ollamaApi.mode || 'local',
      totalEndpoints: this.clients.length,
      healthyEndpoints: this.getHealthyClients().length,
      strategy: CONFIG.ollamaApi.loadBalancing.strategy,
      endpoints: []
    };

    for (const client of this.clients) {
      try {
        const health = await client.getHealth();
        const runningModels = await client.listRunningModels();
        const clientType = this.isRKLlamaEndpoint(client.endpoint) ? 'RKLLama' : 'Ollama';
        
        const processingStatus = client.getProcessingStatus ? client.getProcessingStatus() : {
          activeRequests: 0,
          totalRequests: 0,
          recentRequests: 0,
          averageResponseTime: 0,
          requestHistory: []
        };

        status.endpoints.push({
          url: client.baseURL,
          type: clientType,
          healthy: client.isHealthy,
          priority: client.endpoint.priority,
          runningModels: runningModels.models?.length || 0,
          loadScore: client.getLoadScore(),
          retryCount: client.retryCount,
          lastHealthCheck: client.lastHealthCheck ? new Date(client.lastHealthCheck).toISOString() : 'never',
          version: health.version,
          currentModel: health.currentModel || null,
          processing: processingStatus
        });
      } catch (error) {
        const clientType = this.isRKLlamaEndpoint(client.endpoint) ? 'RKLLama' : 'Ollama';
        const processingStatus = client.getProcessingStatus ? client.getProcessingStatus() : {
          activeRequests: 0,
          totalRequests: 0,
          recentRequests: 0,
          averageResponseTime: 0,
          requestHistory: []
        };

        status.endpoints.push({
          url: client.baseURL,
          type: clientType,
          healthy: false,
          priority: client.endpoint.priority,
          error: error.message,
          retryCount: client.retryCount,
          lastHealthCheck: client.lastHealthCheck ? new Date(client.lastHealthCheck).toISOString() : 'never',
          processing: processingStatus
        });
      }
    }

    return status;
  }

  async isEnabled() {
    const effectiveConfig = await this.getEffectiveConfig();
    return effectiveConfig.ollamaApi.enabled && this.clients.length > 0;
  }

  hasHealthyEndpoints() {
    return this.getHealthyClients().length > 0;
  }

  getMode() {
    return CONFIG.ollamaApi.mode;
  }

  async reinitialize() {
    logger.info('üîÑ Reinicializando pool de APIs Ollama...');
    await this.initialize();
  }

  async loadSavedModels() {
    if (!this.configService) {
      logger.debug('üîß ConfigService n√£o dispon√≠vel, pulando carregamento de modelos salvos');
      return;
    }

    try {
      const config = await this.configService.getConfig();
      const endpoints = config?.ollamaApi?.endpoints || [];
      
      logger.info('üîÑ Carregando modelos salvos para todos os endpoints...');
      
      for (let i = 0; i < this.clients.length; i++) {
        const client = this.clients[i];
        const endpoint = endpoints[i];
        
        // Load models for both Ollama and RKLLama endpoints
        if (endpoint.model && endpoint.enabled) {
          try {
            const endpointType = this.isRKLlamaEndpoint(endpoint) ? 'RKLLama' : 'Ollama';
            logger.info(`üîÑ Carregando modelo salvo ${endpoint.model} para ${endpointType} ${endpoint.url}`);
            
            // Check if endpoint is healthy first
            await client.checkHealth();
            
            if (client.isHealthy) {
              if (this.isRKLlamaEndpoint(endpoint)) {
                // For RKLLama, use loadModel method
                await client.loadModel(endpoint.model);
                logger.success(`‚úÖ Modelo ${endpoint.model} carregado automaticamente em RKLLama ${endpoint.url}`);
              } else {
                // For Ollama, use preloadModel method
                await client.preloadModel(endpoint.model);
                logger.success(`‚úÖ Modelo ${endpoint.model} pr√©-carregado automaticamente em Ollama ${endpoint.url}`);
              }
            } else {
              logger.warn(`‚ö†Ô∏è Endpoint ${endpoint.url} n√£o est√° saud√°vel, pulando carregamento do modelo ${endpoint.model}`);
            }
          } catch (error) {
            const endpointType = this.isRKLlamaEndpoint(endpoint) ? 'RKLLama' : 'Ollama';
            logger.warn(`‚ö†Ô∏è Falha ao carregar modelo ${endpoint.model} para ${endpointType} ${endpoint.url}: ${error.message}`);
          }
        }
      }
      
      logger.info('‚úÖ Carregamento de modelos salvos conclu√≠do');
    } catch (error) {
      logger.error('‚ùå Erro ao carregar modelos salvos:', error);
    }
  }

  destroy() {
    logger.info('üóëÔ∏è Destruindo pool de APIs Ollama...');
    this.stopHealthCheckInterval();
    this.clients = [];
  }
}

export default OllamaAPIPool;