import fs from 'fs/promises';
import path from 'path';
import { Readable } from 'stream';
import { spawn } from 'child_process';
import { WHISPER_CPP_PATH, WHISPER_CPP_MAIN_PATH, MODEL_OBJECT } from 'nodejs-whisper/dist/constants.js';
import { nodewhisper } from 'nodejs-whisper';
import ffmpeg from 'fluent-ffmpeg';
import Utils from '../utils/index.js'; // Ajustar caminho se necess√°rio
import { CONFIG, __dirname } from '../config/index.js'; // Ajustar caminho se necess√°rio
import JobQueue from './jobQueue.js';
import logger from '../utils/logger.js';
import { Ollama } from 'ollama';

// ============ Transcritor de √Åudio ============
class AudioTranscriber {
  constructor() {
    this.queue = new JobQueue(
      CONFIG.queues.whisperConcurrency,
      CONFIG.queues.memoryThresholdGB
    );
    this.ollamaClient = new Ollama({ host: CONFIG.llm.host });
  }

  async transcribeWithAutoDownload(filePath, modelName = CONFIG.audio.model) {
    try {
      logger.debug(`üîÑ Iniciando transcri√ß√£o com auto-download do modelo: ${modelName}`);
      
      const options = {
        modelName: modelName,
        autoDownloadModelName: modelName,
        verbose: true,
        removeWavFileAfterTranscription: false,
        withCuda: false,
        whisperOptions: { 
          outputInText: true, 
          language: CONFIG.audio.language 
        },
        logger: logger
      };

      logger.debug('üöÄ Executando nodejs-whisper com auto-download...');
      const transcription = await nodewhisper(filePath, options);
      
      logger.success(`‚úÖ Transcri√ß√£o conclu√≠da com auto-download. Modelo: ${modelName}`);
      return transcription.trim();
      
    } catch (error) {
      logger.error(`‚ùå Erro na transcri√ß√£o com auto-download:`, error);
      throw new Error(`Falha na transcri√ß√£o com auto-download: ${error.message}`);
    }
  }

  async runWhisper(filePath, options) {
    const execPath = path.join(WHISPER_CPP_PATH, WHISPER_CPP_MAIN_PATH);
    const modelFile = MODEL_OBJECT[options.modelName];
    const modelPath = path.join(WHISPER_CPP_PATH, 'models', modelFile);
    const args = ['-m', modelPath, '-f', filePath, '-otxt', '-l', options.whisperOptions.language];

    // Log detalhado para debug
    logger.debug('üîß Whisper Debug Info:', {
      execPath,
      modelFile,
      modelPath,
      filePath,
      args: args.join(' '),
      cwd: WHISPER_CPP_PATH,
      timeout: CONFIG.audio.timeoutMs
    });

    // Verificar se o execut√°vel existe
    try {
      await fs.access(execPath, fs.constants.F_OK | fs.constants.X_OK);
      logger.debug(`‚úÖ Execut√°vel Whisper encontrado: ${execPath}`);
    } catch (error) {
      logger.error(`‚ùå Execut√°vel Whisper n√£o encontrado ou n√£o execut√°vel: ${execPath}`);
      throw new Error(`Whisper executable not found or not executable: ${execPath}`);
    }

    return new Promise((resolve, reject) => {
      logger.debug(`üöÄ Iniciando processo Whisper: ${execPath} ${args.join(' ')}`);
      
      const proc = spawn(execPath, args, { 
        cwd: WHISPER_CPP_PATH,
        stdio: ['pipe', 'pipe', 'pipe']
      });
      
      let stdout = '';
      let stderr = '';
      
      const timer = setTimeout(() => {
        logger.error('‚è∞ Whisper process timeout ap√≥s', CONFIG.audio.timeoutMs, 'ms');
        proc.kill('SIGKILL');
        reject(new Error(`Whisper process timed out after ${CONFIG.audio.timeoutMs}ms`));
      }, CONFIG.audio.timeoutMs);

      proc.stdout.on('data', d => {
        const data = d.toString();
        stdout += data;
        if (options.verbose) {
          logger.debug('üì§ Whisper STDOUT:', data.trim());
        }
      });

      proc.stderr.on('data', d => {
        const data = d.toString();
        stderr += data;
        logger.debug('üì• Whisper STDERR:', data.trim());
      });

      proc.on('error', err => {
        clearTimeout(timer);
        logger.error('‚ùå Whisper process error:', err);
        reject(err);
      });

      proc.on('close', code => {
        clearTimeout(timer);
        logger.debug(`üèÅ Whisper process finished with code: ${code}`);
        
        if (stdout) logger.debug('üì§ Final STDOUT:', stdout.trim());
        if (stderr) logger.debug('üì• Final STDERR:', stderr.trim());
        
        if (code === 0) {
          logger.debug('‚úÖ Whisper process completed successfully');
          resolve();
        } else {
          const errorMsg = stderr || `Whisper exited with code ${code}`;
          logger.error('‚ùå Whisper process failed:', errorMsg);
          reject(new Error(errorMsg));
        }
      });
    });
  }

  async transcribe(audioBuffer, inputFormat = 'ogg') {
    return this.queue.add(async () => {
      logger.service('üé§ Iniciando transcri√ß√£o de √°udio...');
      logger.verbose(`üìä Audio buffer details:`, {
        size: audioBuffer.length,
        format: inputFormat,
        sizeInMB: (audioBuffer.length / 1024 / 1024).toFixed(2),
        timestamp: new Date().toISOString()
      });
      
      const timestamp = Date.now();
      const tempOutputPath = path.join(__dirname, `audio_${timestamp}.wav`);
      logger.verbose(`üìÅ Arquivo tempor√°rio: ${tempOutputPath}`);

      try {
        // Verifica se o modelo est√° dispon√≠vel
        const modelFile = MODEL_OBJECT[CONFIG.audio.model];
        const modelPath = path.join(WHISPER_CPP_PATH, 'models', modelFile);
        logger.verbose(`üîç Verificando modelo Whisper:`, {
          model: CONFIG.audio.model,
          modelFile,
          modelPath,
          language: CONFIG.audio.language
        });
        
        try {
          await fs.access(modelPath);
          logger.verbose(`‚úÖ Modelo Whisper encontrado e acess√≠vel: ${modelPath}`);
        } catch (error) {
          logger.warn(`‚ö†Ô∏è Modelo Whisper n√£o encontrado: ${modelPath}`);
          logger.info(`üîÑ Tentando baixar automaticamente o modelo '${CONFIG.audio.model}'...`);
          
          try {
            const transcription = await this.transcribeWithAutoDownload(tempOutputPath, CONFIG.audio.model);
            logger.success(`‚úÖ Transcri√ß√£o conclu√≠da com download autom√°tico do modelo`);
            
            // Limpa arquivos tempor√°rios
            await Utils.cleanupFile(tempOutputPath);
            
            return transcription;
          } catch (autoDownloadError) {
            logger.error(`‚ùå Falha no download autom√°tico do modelo:`, autoDownloadError);
            throw new Error(`Modelo Whisper '${CONFIG.audio.model}' n√£o encontrado em ${modelPath} e falha no download autom√°tico: ${autoDownloadError.message}`);
          }
        }

        logger.verbose(`üîÑ Iniciando convers√£o de √°udio com FFMPEG:`, {
          inputFormat,
          outputFormat: 'wav',
          sampleRate: CONFIG.audio.sampleRate,
          outputPath: tempOutputPath
        });

        await new Promise((resolve, reject) => {
          const inputStream = Readable.from(audioBuffer);
          const ffmpegCommand = ffmpeg(inputStream)
            .inputFormat(inputFormat)
            .outputOptions(`-ar ${CONFIG.audio.sampleRate}`)
            .toFormat('wav')
            .on('start', (commandLine) => {
              logger.verbose(`üöÄ FFMPEG comando: ${commandLine}`);
            })
            .on('progress', (progress) => {
              logger.verbose(`‚è≥ FFMPEG progresso: ${progress.percent}%`);
            })
            .on('error', (err) => {
              logger.error('‚ùå Erro no FFMPEG:', err);
              reject(err);
            })
            .on('end', () => {
              logger.verbose('‚úÖ Convers√£o FFMPEG conclu√≠da');
              resolve();
            })
            .save(tempOutputPath);
        });
        
        const options = {
          modelName: CONFIG.audio.model,
          autoDownloadModelName: CONFIG.audio.model,
          verbose: true,
          removeWavFileAfterTranscription: false,
          withCuda: false,
          whisperOptions: { 
            outputInText: true, 
            language: CONFIG.audio.language 
          }
        };
        
        logger.verbose(`üéôÔ∏è Iniciando transcri√ß√£o Whisper:`, {
          model: options.modelName,
          language: options.whisperOptions.language,
          inputFile: tempOutputPath,
          timeout: CONFIG.audio.timeoutMs
        });
        
        // Executa o Whisper com controle de timeout
        const whisperStartTime = Date.now();
        await this.runWhisper(tempOutputPath, options);
        const whisperEndTime = Date.now();
        
        logger.verbose(`‚è±Ô∏è Transcri√ß√£o Whisper conclu√≠da em ${whisperEndTime - whisperStartTime}ms`);
        
        const transcriptionPath = `${tempOutputPath}.txt`;
        logger.verbose(`üìÑ Lendo transcri√ß√£o de: ${transcriptionPath}`);
        
        const transcription = await fs.readFile(transcriptionPath, 'utf8');
        logger.verbose(`üìù Transcri√ß√£o obtida:`, {
          length: transcription.length,
          preview: transcription.substring(0, 100) + (transcription.length > 100 ? '...' : ''),
          wordCount: transcription.split(' ').length
        });
        
        // Usa o m√©todo est√°tico de Utils para limpar arquivos
        logger.verbose(`üßπ Limpando arquivos tempor√°rios...`);
        await Utils.cleanupFile(tempOutputPath);
        await Utils.cleanupFile(transcriptionPath);
        logger.verbose(`‚úÖ Arquivos tempor√°rios removidos`);
        
        const finalTranscription = transcription.trim();
        logger.success(`‚úÖ Transcri√ß√£o conclu√≠da. Resultado: ${finalTranscription.length} caracteres, ${finalTranscription.split(' ').length} palavras`);
        return finalTranscription;
        
      } catch (err) {
        logger.error('‚ùå Erro na transcri√ß√£o de √°udio:', err);
        // Tenta limpar o arquivo tempor√°rio mesmo em caso de erro
        await Utils.cleanupFile(tempOutputPath);
        throw err;
      }
    });
  }

  async transcribeAndSummarize(audioBuffer, inputFormat = 'ogg') {
    try {
      logger.service('üé§ Iniciando transcri√ß√£o e resumo de √°udio...');
      
      const transcription = await this.transcribe(audioBuffer, inputFormat);
      
      logger.service('üß† Gerando resumo com LLM...');
      const summaryPrompt = `Analise a seguinte transcri√ß√£o de √°udio e crie um resumo estruturado e claro:

TRANSCRI√á√ÉO:
"${transcription}"

O resumo deve incluir os principais pontos discutidos, eventos importantes e qualquer informa√ß√£o relevante mencionada. Evite detalhes excessivos e mantenha o foco nos aspectos mais significativos da conversa. O resumo deve ser escrito em portugu√™s e ser facilmente compreens√≠vel.
Mantenha o resumo conciso mas informativo, destacando os pontos mais importantes do √°udio.`;

      const summary = await this.ollamaClient.generate({
        model: CONFIG.llm.model,
        prompt: summaryPrompt,
        stream: false
      });

      logger.success('‚úÖ Transcri√ß√£o e resumo conclu√≠dos.');
      
      return {
        transcription: transcription,
        summary: summary.response,
        combined: `üé§ **TRANSCRI√á√ÉO COMPLETA:**\n\n${transcription}\n\n---\n\n${summary.response}`
      };
      
    } catch (err) {
      logger.error('‚ùå Erro na transcri√ß√£o e resumo de √°udio:', err);
      throw err;
    }
  }
}

export default AudioTranscriber;
